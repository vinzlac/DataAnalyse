import pandas as pd
import os
import argparse
import sys
from datetime import datetime
import re

def detect_value_type(value):
    """
    D√©tecte le type d'une valeur.
    Retourne: 'number', 'date', 'string', ou 'nan'
    """
    if pd.isna(value):
        return 'nan'
    
    # Convertir en string pour l'analyse
    str_value = str(value).strip()
    
    if str_value == '':
        return 'empty'
    
    # Test 1: Est-ce un nombre ?
    try:
        float(str_value)
        return 'number'
    except ValueError:
        pass
    
    # Test 2: Est-ce une date ? (plusieurs formats courants)
    date_formats = [
        '%Y-%m-%d',           # 2023-12-25
        '%d/%m/%Y',           # 25/12/2023
        '%m/%d/%Y',           # 12/25/2023
        '%Y/%m/%d',           # 2023/12/25
        '%d-%m-%Y',           # 25-12-2023
        '%Y-%m-%d %H:%M:%S',  # 2023-12-25 14:30:00
        '%d/%m/%Y %H:%M:%S',  # 25/12/2023 14:30:00
        '%Y-%m-%dT%H:%M:%S',  # ISO format
        '%Y-%m-%dT%H:%M:%SZ', # ISO format with Z
        '%d.%m.%Y',           # 25.12.2023
        '%Y.%m.%d',           # 2023.12.25
    ]
    
    for date_format in date_formats:
        try:
            datetime.strptime(str_value, date_format)
            return 'date'
        except ValueError:
            continue
    
    # Test 3: Pattern de date plus flexible (YYYY, MM, DD pr√©sents)
    # Exemple: "2023-12-25" ou variations
    date_pattern = r'(\d{4}[-/\.]\d{1,2}[-/\.]\d{1,2})|(\d{1,2}[-/\.]\d{1,2}[-/\.]\d{4})'
    if re.match(date_pattern, str_value):
        return 'date'
    
    # Sinon, c'est une string
    return 'string'


def analyze_column_consistency(series):
    """
    Analyse la coh√©rence des types dans une s√©rie pandas.
    Retourne un dictionnaire avec les informations de coh√©rence.
    """
    # Compter les types de valeurs (en excluant les NaN)
    type_counts = {}
    total_values = 0
    nan_count = 0
    
    for value in series:
        value_type = detect_value_type(value)
        
        if value_type == 'nan':
            nan_count += 1
        elif value_type == 'empty':
            continue  # On ignore les valeurs vides
        else:
            total_values += 1
            type_counts[value_type] = type_counts.get(value_type, 0) + 1
    
    # D√©terminer si la colonne est coh√©rente
    unique_types = list(type_counts.keys())
    is_consistent = len(unique_types) <= 1
    
    # Type dominant (excluant NaN)
    dominant_type = None
    if unique_types:
        dominant_type = max(type_counts, key=type_counts.get)
    
    # Si on a des NaN et un seul autre type, supposer que les NaN devraient √™tre de ce type
    expected_type = dominant_type
    if dominant_type and nan_count > 0:
        # Les NaN sont probablement du m√™me type que le type dominant
        pass
    
    return {
        'is_consistent': is_consistent,
        'types_found': unique_types,
        'type_counts': type_counts,
        'dominant_type': dominant_type,
        'total_values': total_values,
        'nan_count': nan_count,
        'inconsistency_details': None if is_consistent else f"M√©lange de types: {', '.join([f'{t}({type_counts[t]})' for t in unique_types])}"
    }


def main():
    parser = argparse.ArgumentParser(
        description="V√©rifie la coh√©rence des types de donn√©es dans les colonnes des fichiers CSV."
    )
    parser.add_argument(
        "--data-dir",
        required=True,
        help="Chemin vers le dossier contenant les fichiers CSV."
    )
    parser.add_argument(
        "--output",
        default="rapport_coherence_donnees.csv",
        help="Chemin de sortie du rapport CSV (par d√©faut: rapport_coherence_donnees.csv)."
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Affiche les d√©tails des colonnes coh√©rentes √©galement."
    )

    args = parser.parse_args()

    data_dir = args.data_dir
    output_path = args.output
    verbose = args.verbose

    if not os.path.exists(data_dir):
        print(f"‚ùå Erreur : le dossier '{data_dir}' n'existe pas.")
        sys.exit(1)

    results = []
    total_files = 0
    total_inconsistencies = 0

    for file_name in os.listdir(data_dir):
        if file_name.endswith(".csv"):
            total_files += 1
            file_path = os.path.join(data_dir, file_name)
            print(f"\nüîç Analyse de {file_name} ...")

            try:
                # Lecture du CSV (auto-d√©tection du s√©parateur)
                df = pd.read_csv(file_path, sep=None, engine="python")
                
                # Nombre total de lignes
                total_rows = len(df)
                
                file_inconsistencies = 0
                
                for column in df.columns:
                    analysis = analyze_column_consistency(df[column])
                    
                    # Ne rapporter que les incoh√©rences, sauf si verbose
                    if not analysis['is_consistent']:
                        file_inconsistencies += 1
                        total_inconsistencies += 1
                        
                        results.append({
                            "fichier": file_name,
                            "total_row_count": total_rows,
                            "colonne": column,
                            "coherent": "NON ‚ùå",
                            "types_detectes": ", ".join(analysis['types_found']),
                            "type_dominant": analysis['dominant_type'] or "N/A",
                            "details": analysis['inconsistency_details'],
                            "nb_valeurs": analysis['total_values'],
                            "nb_nan": analysis['nan_count']
                        })
                        
                        print(f"  ‚ö†Ô∏è  Colonne '{column}': {analysis['inconsistency_details']}")
                    
                    elif verbose:
                        results.append({
                            "fichier": file_name,
                            "total_row_count": total_rows,
                            "colonne": column,
                            "coherent": "OUI ‚úì",
                            "types_detectes": ", ".join(analysis['types_found']) if analysis['types_found'] else "vide",
                            "type_dominant": analysis['dominant_type'] or "N/A",
                            "details": "Coh√©rent",
                            "nb_valeurs": analysis['total_values'],
                            "nb_nan": analysis['nan_count']
                        })
                
                if file_inconsistencies == 0:
                    print(f"  ‚úÖ Toutes les colonnes sont coh√©rentes ({len(df.columns)} colonnes analys√©es)")

            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lors de la lecture de {file_name}: {e}")

    # R√©sum√©
    print(f"\n{'='*60}")
    print(f"üìä R√âSUM√â")
    print(f"{'='*60}")
    print(f"Fichiers analys√©s: {total_files}")
    print(f"Incoh√©rences d√©tect√©es: {total_inconsistencies}")
    
    if not results:
        print("\n‚úÖ Aucune incoh√©rence d√©tect√©e ou aucun CSV trouv√©.")
        sys.exit(0)

    # üìä G√©n√©ration du rapport
    report_df = pd.DataFrame(results)
    
    if not verbose and total_inconsistencies > 0:
        print(f"\n=== Colonnes avec incoh√©rences de types ===")
        print(report_df.to_string(index=False))
    elif verbose:
        print(f"\n=== Rapport complet (toutes les colonnes) ===")
        print(report_df.to_string(index=False))

    # üíæ Export CSV
    report_df.to_csv(output_path, index=False)
    print(f"\n‚úÖ Rapport export√© dans : {output_path}")


if __name__ == "__main__":
    main()

